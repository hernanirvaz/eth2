#!/bin/bash

source /home/eth/eth2/t1

if [[ $cunm != $znm3 && $cunm != $vnm2 ]]; then
  tex 'MONITOR NAO DEVE SER INSTALADO - DEVE FICAR ONDE FICA O MAIN BEACON'
else
  if [[ -f $s2/prometheus.yml ]]; then
    tex 'PROMETHEUS JA INSTALADO'
  else
    tex 'CONFIGURE PROMETHEUS'
    cex 'apt install -y prometheus prometheus-node-exporter'
    t6 mpr
    cd ~
    cat <<-EOF > prometheus.yml
		global:
		  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
		  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
		  # Attach these labels to any time series or alerts when communicating with
		  # external systems (federation, remote storage, Alertmanager).
		  external_labels:
		    monitor: 'lighthouse-monitor'
		# A scrape configuration containing exactly one endpoint to scrape:
		# Here it's Prometheus itself.
		scrape_configs:
		  - job_name: 'node_exporter'
		    static_configs:
		      - targets: ['localhost:9100']
		  - job_name: 'nodes'
		    metrics_path: /metrics
		    static_configs:
		      - targets: ['localhost:5054']
		  - job_name: 'validators'
		    metrics_path: /metrics
		    static_configs:
		      - targets: ['$vip3:5064', 'localhost:5064']
		EOF
    sudo mv prometheus.yml $s2/prometheus.yml
    tex 'CONFIGURE GRAFANA'
    wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
    sudo add-apt-repository -y 'deb https://packages.grafana.com/oss/deb stable main'
    sudo apt update -y
    sudo apt install -y grafana
    t6 me
    t6 ma
  fi
  nex "\nConfigure Grafana Login admin:admin http://$(uname -n):3000 & Change password $V & DATASOURCE URL http://127.0.0.1:9090\n"
  nex 'Import some dashboards from the dashboards directory in https://github.com/sigp/lighthouse-metrics'
  nex 'In the Grafana UI, go to Dashboards -> Manage -> Import -> Upload .json file.'
  nex 'The Summary.json dashboard is a good place to start.\n'
fi
